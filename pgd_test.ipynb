{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f94fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 16:54:39.276269: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/reshma/Documents/Coding/capstone_project/attack/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/reshma/Documents/Coding/capstone_project/attack/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/reshma/Documents/Coding/capstone_project/attack/lib/python3.9/site-packages/art/estimators/certification/__init__.py:30: UserWarning: PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\n",
      "  warnings.warn(\"PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"All libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4314e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'CIC-Darknet2020.csv'\n",
    "TARGET_LABELS = ['Tor', 'Non-Tor', 'VPN', 'NonVPN']\n",
    "\n",
    "MODEL_PATH = 'model-defended-v2.h5'\n",
    "SCALER_PATH = 'scaler-multi.pkl'\n",
    "\n",
    "PGD_EPS = 0.1\n",
    "PGD_EPS_STEP = 0.01 \n",
    "PGD_MAX_ITER = 40\n",
    "PGD_BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd5b0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multi_class_test_data():\n",
    "    try:\n",
    "        df = pd.read_csv(DATA_PATH)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: '{DATA_PATH}' not found.\")\n",
    "        return None\n",
    "\n",
    "    df.columns = [*df.columns[:-2], 'Label', 'Label_Type']\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    df_multi = df[df['Label'].isin(TARGET_LABELS)].copy()\n",
    "\n",
    "    non_feature_cols = ['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp', 'Label', 'Label_Type']\n",
    "    X = df_multi.drop(columns=non_feature_cols).apply(pd.to_numeric)\n",
    "    y = df_multi['Label']\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    n_classes = len(le.classes_)\n",
    "    target_names = le.classes_\n",
    "    y_ohe = to_categorical(y_encoded, num_classes=n_classes)\n",
    "    \n",
    "    print(\"--- Class Encoding Mapping ---\")\n",
    "    for index, label in enumerate(le.classes_):\n",
    "        print(f\"Class Index {index} -> {label}\")\n",
    "\n",
    "    X_train, X_test, y_train_ohe, y_test_ohe, y_train_encoded, y_test_encoded = train_test_split(\n",
    "        X, y_ohe, y_encoded,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_encoded\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        scaler = joblib.load(SCALER_PATH)\n",
    "        print(f\"\\nScaler '{SCALER_PATH}' loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: '{SCALER_PATH}' not found. Did you run the baseline notebook?\")\n",
    "        return None\n",
    "        \n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    n_features = X_test_scaled.shape[1]\n",
    "    X_test_cnn = X_test_scaled.reshape((X_test_scaled.shape[0], n_features, 1))\n",
    "    \n",
    "    print(f\"Data preparation complete. Found {n_features} features and {n_classes} classes.\")\n",
    "    \n",
    "    return X_test_cnn, y_test_ohe, y_test_encoded, target_names, n_features, n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b83886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_art_classifier_multi(model_path, n_features, n_classes):\n",
    "    try:\n",
    "        model = load_model(model_path)\n",
    "        print(f\"Model '{model_path}' loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Model file '{model_path}' not found or failed to load.\")\n",
    "        print(f\"Details: {e}\")\n",
    "        return None, None\n",
    "        \n",
    "    loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "    classifier = TensorFlowV2Classifier(\n",
    "        model=model,\n",
    "        loss_object=loss_object,\n",
    "        input_shape=(n_features, 1),\n",
    "        nb_classes=n_classes, \n",
    "        channels_first=False\n",
    "    )\n",
    "    \n",
    "    return model, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc7b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_attack_multi(y_true_encoded, y_pred_probs, attack_name, target_names):\n",
    "    y_pred_encoded = np.argmax(y_pred_probs, axis=1)\n",
    "    \n",
    "    acc = accuracy_score(y_true_encoded, y_pred_encoded)\n",
    "    \n",
    "    print(f\"\\n--- {attack_name} Metrics ---\")\n",
    "    print(f\"Accuracy: {acc * 100:.4f}%\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true_encoded, y_pred_encoded, target_names=target_names))\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true_encoded, y_pred_encoded))\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f5ca9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Class Encoding Mapping ---\n",
      "Class Index 0 -> Non-Tor\n",
      "Class Index 1 -> NonVPN\n",
      "Class Index 2 -> Tor\n",
      "Class Index 3 -> VPN\n",
      "\n",
      "Scaler 'scaler-multi.pkl' loaded successfully.\n",
      "Data preparation complete. Found 76 features and 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'model-defended-v2.h5' loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "data = load_multi_class_test_data()\n",
    "\n",
    "if data:\n",
    "    X_test_cnn, y_test_ohe, y_test_encoded, target_names, n_features, n_classes = data\n",
    "    \n",
    "    X_test_art = X_test_cnn.astype(np.float32)\n",
    "\n",
    "    model, classifier = get_art_classifier_multi(MODEL_PATH, n_features, n_classes)\n",
    "else:\n",
    "    print(\"Data loading failed. Cannot proceed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcfd46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating baseline (clean) model performance...\n",
      "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step\n",
      "\n",
      "--- Baseline (Clean) Metrics ---\n",
      "Accuracy: 95.9135%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Non-Tor       1.00      0.99      1.00     22079\n",
      "      NonVPN       0.88      0.86      0.87      4772\n",
      "         Tor       0.90      0.87      0.89       279\n",
      "         VPN       0.86      0.90      0.88      4584\n",
      "\n",
      "    accuracy                           0.96     31714\n",
      "   macro avg       0.91      0.91      0.91     31714\n",
      "weighted avg       0.96      0.96      0.96     31714\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21911   120     1    47]\n",
      " [   29  4120    22   601]\n",
      " [    0    23   244    12]\n",
      " [   12   426     3  4143]]\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    print(\"\\nEvaluating baseline (clean) model performance...\")\n",
    "    y_pred_clean_probs = model.predict(X_test_art)\n",
    "    \n",
    "    clean_acc = evaluate_attack_multi(y_test_encoded, y_pred_clean_probs, \n",
    "                                      \"Baseline (Clean)\", target_names)\n",
    "else:\n",
    "    print(\"Model not loaded. Skipping baseline evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d2c3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Starting PGD Attack (Epsilon = 0.1, Iterations = 40)\n",
      "==================================================\n",
      "\n",
      "Generating adversarial examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PGD - Batches: 496it [19:34,  2.13s/it]2025-11-01 17:15:30.879115: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model on Adversarial Examples...\n",
      "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step\n",
      "\n",
      "--- PGD Attack (eps=0.1) Metrics ---\n",
      "Accuracy: 1.0185%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Non-Tor       0.25      0.01      0.01     22079\n",
      "      NonVPN       0.00      0.01      0.00      4772\n",
      "         Tor       0.25      0.52      0.33       279\n",
      "         VPN       0.00      0.00      0.00      4584\n",
      "\n",
      "    accuracy                           0.01     31714\n",
      "   macro avg       0.12      0.14      0.09     31714\n",
      "weighted avg       0.17      0.01      0.01     31714\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  124 11607    14 10334]\n",
      " [  252    48   431  4041]\n",
      " [   18    72   146    43]\n",
      " [  107  4468     4     5]]\n",
      "\n",
      "==================================================\n",
      "Baseline (Clean) Accuracy: 95.9135%\n",
      "Adversarial (PGD) Accuracy: 1.0185%\n",
      "Accuracy Drop: 94.8950%\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "if 'classifier' in locals() and 'clean_acc' in locals():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Starting PGD Attack (Epsilon = {PGD_EPS}, Iterations = {PGD_MAX_ITER})\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "    attack = ProjectedGradientDescent(\n",
    "        classifier,\n",
    "        eps=PGD_EPS,\n",
    "        eps_step=PGD_EPS_STEP,\n",
    "        max_iter=PGD_MAX_ITER,\n",
    "        batch_size=PGD_BATCH_SIZE,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    print(f\"Generating adversarial examples...\")\n",
    "    X_test_adv = attack.generate(x=X_test_art, y=y_test_ohe)\n",
    "    \n",
    "    print(\"\\nEvaluating model on Adversarial Examples...\")\n",
    "    y_pred_adv_probs = model.predict(X_test_adv)\n",
    "    \n",
    "    adv_acc = evaluate_attack_multi(y_test_encoded, y_pred_adv_probs, \n",
    "                                    f\"PGD Attack (eps={PGD_EPS})\", target_names)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Baseline (Clean) Accuracy: {clean_acc * 100:.4f}%\")\n",
    "    print(f\"Adversarial (PGD) Accuracy: {adv_acc * 100:.4f}%\")\n",
    "    print(f\"Accuracy Drop: {(clean_acc - adv_acc) * 100:.4f}%\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "else:\n",
    "    print(\"Classifier or clean accuracy not found. Skipping attack.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
