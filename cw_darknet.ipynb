{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7ae7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahima/Desktop/ENC/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/mahima/Desktop/ENC/env/lib/python3.12/site-packages/art/estimators/certification/__init__.py:30: UserWarning: PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\n",
      "  warnings.warn(\"PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from art.attacks.evasion import CarliniL2Method\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"All libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6692cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'CIC-Darknet2020.csv'\n",
    "TARGET_LABELS = ['Tor', 'Non-Tor', 'VPN', 'NonVPN']\n",
    "\n",
    "MODEL_PATH = 'model-multi.h5'\n",
    "SCALER_PATH = 'scaler-multi.pkl'\n",
    "\n",
    "CW_CONFIDENCE = 0.0\n",
    "CW_MAX_ITER = 10\n",
    "CW_BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874922f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multi_class_test_data():\n",
    "    try:\n",
    "        df = pd.read_csv(DATA_PATH)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: '{DATA_PATH}' not found.\")\n",
    "        return None\n",
    "\n",
    "    df.columns = [*df.columns[:-2], 'Label', 'Label_Type']\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    df_multi = df[df['Label'].isin(TARGET_LABELS)].copy()\n",
    "\n",
    "    non_feature_cols = ['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp', 'Label', 'Label_Type']\n",
    "    X = df_multi.drop(columns=non_feature_cols).apply(pd.to_numeric)\n",
    "    y = df_multi['Label']\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    n_classes = len(le.classes_)\n",
    "    target_names = le.classes_\n",
    "    y_ohe = to_categorical(y_encoded, num_classes=n_classes)\n",
    "    \n",
    "    print(\"--- Class Encoding Mapping ---\")\n",
    "    for index, label in enumerate(le.classes_):\n",
    "        print(f\"Class Index {index} -> {label}\")\n",
    "\n",
    "    X_train, X_test, y_train_ohe, y_test_ohe, y_train_encoded, y_test_encoded = train_test_split(\n",
    "        X, y_ohe, y_encoded,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_encoded\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        scaler = joblib.load(SCALER_PATH)\n",
    "        print(f\"\\nScaler '{SCALER_PATH}' loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: '{SCALER_PATH}' not found. Did you run the baseline notebook?\")\n",
    "        return None\n",
    "        \n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    n_features = X_test_scaled.shape[1]\n",
    "    X_test_cnn = X_test_scaled.reshape((X_test_scaled.shape[0], n_features, 1))\n",
    "    \n",
    "    print(f\"Data preparation complete. Found {n_features} features and {n_classes} classes.\")\n",
    "    \n",
    "    return X_test_cnn, y_test_ohe, y_test_encoded, target_names, n_features, n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c89c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_art_classifier_multi(model_path, n_features, n_classes):\n",
    "    try:\n",
    "        model = load_model(model_path)\n",
    "        print(f\"Model '{model_path}' loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Model file '{model_path}' not found or failed to load.\")\n",
    "        print(f\"Details: {e}\")\n",
    "        return None, None\n",
    "        \n",
    "    loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "    classifier = TensorFlowV2Classifier(\n",
    "        model=model,\n",
    "        loss_object=loss_object,\n",
    "        input_shape=(n_features, 1),\n",
    "        nb_classes=n_classes,\n",
    "        channels_first=False\n",
    "    )\n",
    "    \n",
    "    return model, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05104b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_attack_multi(y_true_encoded, y_pred_probs, attack_name, target_names):\n",
    "    y_pred_encoded = np.argmax(y_pred_probs, axis=1)\n",
    "    \n",
    "    acc = accuracy_score(y_true_encoded, y_pred_encoded)\n",
    "    \n",
    "    print(f\"\\n--- {attack_name} Metrics ---\")\n",
    "    print(f\"Accuracy: {acc * 100:.4f}%\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true_encoded, y_pred_encoded, target_names=target_names))\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true_encoded, y_pred_encoded))\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38a17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Class Encoding Mapping ---\n",
      "Class Index 0 -> Non-Tor\n",
      "Class Index 1 -> NonVPN\n",
      "Class Index 2 -> Tor\n",
      "Class Index 3 -> VPN\n",
      "\n",
      "Scaler 'scaler-multi.pkl' loaded successfully.\n",
      "Data preparation complete. Found 76 features and 4 classes.\n",
      "Model 'model-multi.h5' loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "data = load_multi_class_test_data()\n",
    "\n",
    "if data:\n",
    "    X_test_cnn, y_test_ohe, y_test_encoded, target_names, n_features, n_classes = data\n",
    "    X_test_art = X_test_cnn.astype(np.float32)\n",
    "\n",
    "    model, classifier = get_art_classifier_multi(MODEL_PATH, n_features, n_classes)\n",
    "else:\n",
    "    print(\"Data loading failed. Cannot proceed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65e1733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating baseline (clean) model performance...\n",
      "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\n",
      "--- Baseline (Clean) Metrics ---\n",
      "Accuracy: 95.3585%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Non-Tor       1.00      0.99      0.99     22079\n",
      "      NonVPN       0.86      0.85      0.85      4772\n",
      "         Tor       0.82      0.87      0.85       279\n",
      "         VPN       0.86      0.88      0.87      4584\n",
      "\n",
      "    accuracy                           0.95     31714\n",
      "   macro avg       0.88      0.90      0.89     31714\n",
      "weighted avg       0.95      0.95      0.95     31714\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21885   137     1    56]\n",
      " [   43  4073    48   608]\n",
      " [    0    27   244     8]\n",
      " [   19   520     5  4040]]\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals():\n",
    "    print(\"\\nEvaluating baseline (clean) model performance...\")\n",
    "    y_pred_clean_probs = model.predict(X_test_art)\n",
    "    \n",
    "    clean_acc = evaluate_attack_multi(y_test_encoded, y_pred_clean_probs, \n",
    "                                      \"Baseline (Clean)\", target_names)\n",
    "else:\n",
    "    print(\"Model not loaded. Skipping baseline evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a028cccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Starting C&W Attack (Iterations = 10)\n",
      "WARNING: This attack is VERY slow. Please be patient.\n",
      "==================================================\n",
      "\n",
      "Generating adversarial examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2:   0%|          | 0/992 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "C&W L_2: 100%|██████████| 992/992 [3:56:55<00:00, 14.33s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model on Adversarial Examples...\n",
      "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\n",
      "--- C&W Attack (iter=10) Metrics ---\n",
      "Accuracy: 10.0303%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Non-Tor       0.55      0.13      0.21     22079\n",
      "      NonVPN       0.00      0.02      0.01      4772\n",
      "         Tor       0.44      0.77      0.56       279\n",
      "         VPN       0.01      0.01      0.01      4584\n",
      "\n",
      "    accuracy                           0.10     31714\n",
      "   macro avg       0.25      0.23      0.20     31714\n",
      "weighted avg       0.39      0.10      0.15     31714\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2818 15119    32  4110]\n",
      " [ 2176    81   221  2294]\n",
      " [    0    50   215    14]\n",
      " [  153  4344    20    67]]\n",
      "\n",
      "==================================================\n",
      "Baseline (Clean) Accuracy: 95.3585%\n",
      "Adversarial (C&W) Accuracy: 10.0303%\n",
      "Accuracy Drop: 85.3282%\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "if 'classifier' in locals() and 'clean_acc' in locals():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Starting C&W Attack (Iterations = {CW_MAX_ITER})\")\n",
    "    print(\"WARNING: This attack is VERY slow. Please be patient.\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "    attack = CarliniL2Method(\n",
    "        classifier,\n",
    "        confidence=CW_CONFIDENCE,\n",
    "        max_iter=CW_MAX_ITER,\n",
    "        batch_size=CW_BATCH_SIZE,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    print(f\"Generating adversarial examples...\")\n",
    "    X_test_adv = attack.generate(x=X_test_art, y=y_test_ohe)\n",
    "    \n",
    "    print(\"\\nEvaluating model on Adversarial Examples...\")\n",
    "    y_pred_adv_probs = model.predict(X_test_adv)\n",
    "    \n",
    "    adv_acc = evaluate_attack_multi(y_test_encoded, y_pred_adv_probs, \n",
    "                                    f\"C&W Attack (iter={CW_MAX_ITER})\", target_names)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Baseline (Clean) Accuracy: {clean_acc * 100:.4f}%\")\n",
    "    print(f\"Adversarial (C&W) Accuracy: {adv_acc * 100:.4f}%\")\n",
    "    print(f\"Accuracy Drop: {(clean_acc - adv_acc) * 100:.4f}%\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "else:\n",
    "    print(\"Classifier or clean accuracy not found. Skipping attack.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
