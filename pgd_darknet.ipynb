{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f94fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahima/Desktop/ENC/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/mahima/Desktop/ENC/env/lib/python3.12/site-packages/art/estimators/certification/__init__.py:30: UserWarning: PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\n",
      "  warnings.warn(\"PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"All libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4314e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'CIC-Darknet2020.csv'\n",
    "TARGET_LABELS = ['Tor', 'Non-Tor', 'VPN', 'NonVPN']\n",
    "\n",
    "MODEL_PATH = 'model-multi.h5'\n",
    "SCALER_PATH = 'scaler-multi.pkl'\n",
    "\n",
    "PGD_EPS = 0.1\n",
    "PGD_EPS_STEP = 0.01\n",
    "PGD_MAX_ITER = 40 \n",
    "PGD_BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd5b0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multi_class_test_data():\n",
    "    try:\n",
    "        df = pd.read_csv(DATA_PATH)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: '{DATA_PATH}' not found.\")\n",
    "        return None\n",
    "\n",
    "    df.columns = [*df.columns[:-2], 'Label', 'Label_Type']\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    df_multi = df[df['Label'].isin(TARGET_LABELS)].copy()\n",
    "\n",
    "    non_feature_cols = ['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp', 'Label', 'Label_Type']\n",
    "    X = df_multi.drop(columns=non_feature_cols).apply(pd.to_numeric)\n",
    "    y = df_multi['Label']\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    n_classes = len(le.classes_)\n",
    "    target_names = le.classes_\n",
    "    y_ohe = to_categorical(y_encoded, num_classes=n_classes)\n",
    "    \n",
    "    print(\"--- Class Encoding Mapping ---\")\n",
    "    for index, label in enumerate(le.classes_):\n",
    "        print(f\"Class Index {index} -> {label}\")\n",
    "\n",
    "    X_train, X_test, y_train_ohe, y_test_ohe, y_train_encoded, y_test_encoded = train_test_split(\n",
    "        X, y_ohe, y_encoded,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_encoded\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        scaler = joblib.load(SCALER_PATH)\n",
    "        print(f\"\\nScaler '{SCALER_PATH}' loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: '{SCALER_PATH}' not found. Did you run the baseline notebook?\")\n",
    "        return None\n",
    "        \n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    n_features = X_test_scaled.shape[1]\n",
    "    X_test_cnn = X_test_scaled.reshape((X_test_scaled.shape[0], n_features, 1))\n",
    "    \n",
    "    print(f\"Data preparation complete. Found {n_features} features and {n_classes} classes.\")\n",
    "    \n",
    "    return X_test_cnn, y_test_ohe, y_test_encoded, target_names, n_features, n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b83886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_art_classifier_multi(model_path, n_features, n_classes):\n",
    "    try:\n",
    "        model = load_model(model_path)\n",
    "        print(f\"Model '{model_path}' loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Model file '{model_path}' not found or failed to load.\")\n",
    "        print(f\"Details: {e}\")\n",
    "        return None, None\n",
    "        \n",
    "    loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "    classifier = TensorFlowV2Classifier(\n",
    "        model=model,\n",
    "        loss_object=loss_object,\n",
    "        input_shape=(n_features, 1),\n",
    "        nb_classes=n_classes,\n",
    "        channels_first=False\n",
    "    )\n",
    "    \n",
    "    return model, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc7b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_attack_multi(y_true_encoded, y_pred_probs, attack_name, target_names):\n",
    "    y_pred_encoded = np.argmax(y_pred_probs, axis=1)\n",
    "    \n",
    "    acc = accuracy_score(y_true_encoded, y_pred_encoded)\n",
    "    \n",
    "    print(f\"\\n--- {attack_name} Metrics ---\")\n",
    "    print(f\"Accuracy: {acc * 100:.4f}%\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true_encoded, y_pred_encoded, target_names=target_names))\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true_encoded, y_pred_encoded))\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f5ca9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Class Encoding Mapping ---\n",
      "Class Index 0 -> Non-Tor\n",
      "Class Index 1 -> NonVPN\n",
      "Class Index 2 -> Tor\n",
      "Class Index 3 -> VPN\n",
      "\n",
      "Scaler 'scaler-multi.pkl' loaded successfully.\n",
      "Data preparation complete. Found 76 features and 4 classes.\n",
      "Model 'model-multi.h5' loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "data = load_multi_class_test_data()\n",
    "\n",
    "if data:\n",
    "    X_test_cnn, y_test_ohe, y_test_encoded, target_names, n_features, n_classes = data\n",
    "    \n",
    "    X_test_art = X_test_cnn.astype(np.float32)\n",
    "\n",
    "    model, classifier = get_art_classifier_multi(MODEL_PATH, n_features, n_classes)\n",
    "else:\n",
    "    print(\"Data loading failed. Cannot proceed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adcfd46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating baseline (clean) model performance...\n",
      "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "\n",
      "--- Baseline (Clean) Metrics ---\n",
      "Accuracy: 95.3585%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Non-Tor       1.00      0.99      0.99     22079\n",
      "      NonVPN       0.86      0.85      0.85      4772\n",
      "         Tor       0.82      0.87      0.85       279\n",
      "         VPN       0.86      0.88      0.87      4584\n",
      "\n",
      "    accuracy                           0.95     31714\n",
      "   macro avg       0.88      0.90      0.89     31714\n",
      "weighted avg       0.95      0.95      0.95     31714\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21885   137     1    56]\n",
      " [   43  4073    48   608]\n",
      " [    0    27   244     8]\n",
      " [   19   520     5  4040]]\n"
     ]
    }
   ],
   "source": [
    "# 3. Evaluate baseline (clean) accuracy\n",
    "if 'model' in locals():\n",
    "    print(\"\\nEvaluating baseline (clean) model performance...\")\n",
    "    # Use the original Keras model for prediction\n",
    "    y_pred_clean_probs = model.predict(X_test_art)\n",
    "    \n",
    "    # Evaluate using our helper\n",
    "    clean_acc = evaluate_attack_multi(y_test_encoded, y_pred_clean_probs, \n",
    "                                      \"Baseline (Clean)\", target_names)\n",
    "else:\n",
    "    print(\"Model not loaded. Skipping baseline evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2d2c3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Starting PGD Attack (Epsilon = 0.1, Iterations = 40)\n",
      "==================================================\n",
      "\n",
      "Generating adversarial examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                       2025-10-31 18:45:43.583126: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model on Adversarial Examples...\n",
      "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\n",
      "--- PGD Attack (eps=0.1) Metrics ---\n",
      "Accuracy: 8.5514%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Non-Tor       0.08      0.01      0.02     22079\n",
      "      NonVPN       0.02      0.07      0.03      4772\n",
      "         Tor       0.40      0.80      0.54       279\n",
      "         VPN       0.20      0.42      0.27      4584\n",
      "\n",
      "    accuracy                           0.09     31714\n",
      "   macro avg       0.18      0.32      0.21     31714\n",
      "weighted avg       0.09      0.09      0.06     31714\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  239 15974    43  5823]\n",
      " [ 2437   331   263  1741]\n",
      " [    8    31   223    17]\n",
      " [  348  2295    22  1919]]\n",
      "\n",
      "==================================================\n",
      "Baseline (Clean) Accuracy: 95.3585%\n",
      "Adversarial (PGD) Accuracy: 8.5514%\n",
      "Accuracy Drop: 86.8071%\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 4. Initialize and Generate PGD Attack\n",
    "if 'classifier' in locals() and 'clean_acc' in locals():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Starting PGD Attack (Epsilon = {PGD_EPS}, Iterations = {PGD_MAX_ITER})\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "    # [NEW] Create the PGD attack\n",
    "    attack = ProjectedGradientDescent(\n",
    "        classifier,\n",
    "        eps=PGD_EPS,\n",
    "        eps_step=PGD_EPS_STEP,\n",
    "        max_iter=PGD_MAX_ITER,\n",
    "        batch_size=PGD_BATCH_SIZE,\n",
    "        verbose=True  # PGD supports verbose, it will show a progress bar\n",
    "    )\n",
    "\n",
    "    print(f\"Generating adversarial examples...\")\n",
    "    # We MUST use the one-hot encoded labels (y_test_ohe) to guide the attack\n",
    "    X_test_adv = attack.generate(x=X_test_art, y=y_test_ohe)\n",
    "    \n",
    "    print(\"\\nEvaluating model on Adversarial Examples...\")\n",
    "    # Use the original Keras model to predict on the new poison data\n",
    "    y_pred_adv_probs = model.predict(X_test_adv)\n",
    "    \n",
    "    # Evaluate using our helper\n",
    "    adv_acc = evaluate_attack_multi(y_test_encoded, y_pred_adv_probs, \n",
    "                                    f\"PGD Attack (eps={PGD_EPS})\", target_names)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Baseline (Clean) Accuracy: {clean_acc * 100:.4f}%\")\n",
    "    print(f\"Adversarial (PGD) Accuracy: {adv_acc * 100:.4f}%\")\n",
    "    print(f\"Accuracy Drop: {(clean_acc - adv_acc) * 100:.4f}%\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "else:\n",
    "    print(\"Classifier or clean accuracy not found. Skipping attack.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
