{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dc8f06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahima/Desktop/ENC/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/mahima/Desktop/ENC/env/lib/python3.12/site-packages/art/estimators/certification/__init__.py:30: UserWarning: PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\n",
      "  warnings.warn(\"PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.evasion import CarliniL2Method\n",
    "\n",
    "# Suppress warnings\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9de30a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and data...\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "CW_CONFIDENCE = 0.0\n",
    "CW_MAX_ITER = 10\n",
    "CW_BATCH_SIZE = 32\n",
    "\n",
    "print(\"Loading model and data...\")\n",
    "model = load_model('ids_model.h5')\n",
    "print(\"Model loaded.\")\n",
    "X_test = np.load('X_test_ids.npy')\n",
    "y_test_ohe = np.load('y_test_ids_ohe.npy')\n",
    "y_test_int = np.load('y_test_ids_int.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b0a0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded. X_test shape: (210876, 78, 1)\n",
      "Classes: ['BENIGN' 'Bot' 'DDoS' 'DoS GoldenEye' 'DoS Hulk' 'DoS Slowhttptest'\n",
      " 'DoS slowloris' 'FTP-Patator' 'Heartbleed' 'Infiltration' 'PortScan'\n",
      " 'SSH-Patator']\n",
      "\n",
      "Checking baseline accuracy...\n",
      "Baseline (Clean) Accuracy: 90.87%\n",
      "ART Classifier created.\n",
      "\n",
      "==================================================\n",
      "Starting C&W Attack (Iterations = 10)\n",
      "==================================================\n",
      "\n",
      "Generating adversarial examples on 5000 samples...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 157/157 [2:55:42<00:00, 67.15s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model on Adversarial Examples...\n"
     ]
    }
   ],
   "source": [
    "label_encoder = joblib.load('label_encoder_ids.joblib')\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "print(f\"Data loaded. X_test shape: {X_test.shape}\")\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "print(\"\\nChecking baseline accuracy...\")\n",
    "y_pred_clean = model.predict(X_test, verbose=0)\n",
    "y_pred_clean_int = np.argmax(y_pred_clean, axis=1)\n",
    "\n",
    "clean_acc = accuracy_score(y_test_int, y_pred_clean_int)\n",
    "print(f\"Baseline (Clean) Accuracy: {clean_acc * 100:.2f}%\")\n",
    "\n",
    "classifier = KerasClassifier(model=model, clip_values=(X_test.min(), X_test.max()))\n",
    "print(\"ART Classifier created.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Starting C&W Attack (Iterations = {CW_MAX_ITER})\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "attack = CarliniL2Method(\n",
    "    classifier,\n",
    "    confidence=CW_CONFIDENCE,\n",
    "    max_iter=CW_MAX_ITER,\n",
    "    batch_size=CW_BATCH_SIZE,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "n_samples = 5000\n",
    "X_test_subset = X_test[:n_samples]\n",
    "y_test_subset_ohe = y_test_ohe[:n_samples]\n",
    "y_test_subset_int = y_test_int[:n_samples]\n",
    "\n",
    "print(f\"Generating adversarial examples on {n_samples} samples...\")\n",
    "\n",
    "X_test_adv = attack.generate(x=X_test_subset, y=y_test_subset_ohe)\n",
    "\n",
    "print(\"\\nEvaluating model on Adversarial Examples...\")\n",
    "y_pred_adv = model.predict(X_test_adv, verbose=0)\n",
    "y_pred_adv_int = np.argmax(y_pred_adv, axis=1)\n",
    "\n",
    "adv_acc = accuracy_score(y_test_subset_int, y_pred_adv_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ee3b93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "RESULTS: C&W Attack (iter=10)\n",
      "==================================================\n",
      "Clean Accuracy (on subset): 90.56%\n",
      "Attack Accuracy:            44.92%\n",
      "Accuracy Drop:              45.95%\n",
      "==================================================\n",
      "\n",
      "Classification Report (Adversarial):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          BENIGN       0.60      0.47      0.52      2426\n",
      "             Bot       0.00      0.00      0.00         9\n",
      "            DDoS       0.65      0.57      0.61       560\n",
      "   DoS GoldenEye       0.05      0.26      0.08        50\n",
      "        DoS Hulk       0.71      0.65      0.68      1073\n",
      "DoS Slowhttptest       0.08      0.34      0.14        29\n",
      "   DoS slowloris       0.06      0.16      0.09        31\n",
      "     FTP-Patator       0.00      0.00      0.00        41\n",
      "      Heartbleed       0.00      0.00      0.00         0\n",
      "    Infiltration       0.00      0.00      0.00         0\n",
      "        PortScan       0.46      0.08      0.14       756\n",
      "     SSH-Patator       0.01      0.16      0.02        25\n",
      "\n",
      "        accuracy                           0.45      5000\n",
      "       macro avg       0.22      0.22      0.19      5000\n",
      "    weighted avg       0.58      0.45      0.49      5000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1133  268   99  152  207   98   52   44   20  118   52  183]\n",
      " [   4    0    0    0    0    0    0    0    0    0    2    3]\n",
      " [ 131    0  319   38   60    0    0    0    0   12    0    0]\n",
      " [  29    0    2   13    3    0    1    0    2    0    0    0]\n",
      " [ 240    0   71   59  702    0    0    0    1    0    0    0]\n",
      " [   5    0    0    1    0   10   13    0    0    0    0    0]\n",
      " [   5    0    0    0    0   10    5    1    0    3    7    0]\n",
      " [  23    0    0    0    0    0    0    0    0    0   10    8]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 317  101    0    0   22    0    9   12    0    0   60  235]\n",
      " [  15    6    0    0    0    0    0    0    0    0    0    4]]\n",
      "\n",
      "✓ C&W attack completed successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"RESULTS: C&W Attack (iter={CW_MAX_ITER})\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Clean Accuracy (on subset): {accuracy_score(y_test_subset_int, np.argmax(model.predict(X_test_subset, verbose=0), axis=1)) * 100:.2f}%\")\n",
    "print(f\"Attack Accuracy:            {adv_acc * 100:.2f}%\")\n",
    "print(f\"Accuracy Drop:              {(clean_acc - adv_acc) * 100:.2f}%\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nClassification Report (Adversarial):\")\n",
    "print(classification_report(y_test_subset_int, y_pred_adv_int, target_names=class_names, zero_division=0))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_subset_int, y_pred_adv_int))\n",
    "\n",
    "print(\"\\n✓ C&W attack completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1942988b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving C&W adversarial data for defense models...\n",
      "✓ Saved: X_adv_cw_ids.npy\n",
      "✓ Saved: y_test_cw_ids_int.npy\n",
      "✓ Saved: y_test_cw_ids_ohe.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Saving C&W adversarial data for defense models...\")\n",
    "\n",
    "file_x_adv = 'X_adv_cw_ids.npy'\n",
    "file_y_int = 'y_test_cw_ids_int.npy'\n",
    "file_y_ohe = 'y_test_cw_ids_ohe.npy'\n",
    "\n",
    "np.save(file_x_adv, X_test_adv)\n",
    "np.save(file_y_int, y_test_subset_int)\n",
    "np.save(file_y_ohe, y_test_subset_ohe)\n",
    "\n",
    "print(f\"✓ Saved: {file_x_adv}\")\n",
    "print(f\"✓ Saved: {file_y_int}\")\n",
    "print(f\"✓ Saved: {file_y_ohe}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
