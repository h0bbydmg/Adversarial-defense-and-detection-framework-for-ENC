{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d83ca3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahima/Desktop/ENC/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/mahima/Desktop/ENC/env/lib/python3.12/site-packages/art/estimators/certification/__init__.py:30: UserWarning: PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\n",
      "  warnings.warn(\"PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "\n",
    "# Suppress warnings\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575431df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and data...\n",
      "Model loaded.\n",
      "Data loaded. X_test shape: (210876, 78, 1)\n",
      "Classes: ['BENIGN' 'Bot' 'DDoS' 'DoS GoldenEye' 'DoS Hulk' 'DoS Slowhttptest'\n",
      " 'DoS slowloris' 'FTP-Patator' 'Heartbleed' 'Infiltration' 'PortScan'\n",
      " 'SSH-Patator']\n",
      "\n",
      "Checking baseline accuracy...\n",
      "Baseline (Clean) Accuracy: 90.87%\n",
      "ART Classifier created.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading model and data...\")\n",
    "\n",
    "model = load_model('ids_model.h5')\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "X_test = np.load('X_test_ids.npy')\n",
    "y_test_ohe = np.load('y_test_ids_ohe.npy')\n",
    "y_test_int = np.load('y_test_ids_int.npy')\n",
    "\n",
    "label_encoder = joblib.load('label_encoder_ids.joblib')\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "print(f\"Data loaded. X_test shape: {X_test.shape}\")\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "print(\"\\nChecking baseline accuracy...\")\n",
    "y_pred_clean = model.predict(X_test, verbose=0)\n",
    "y_pred_clean_int = np.argmax(y_pred_clean, axis=1)\n",
    "\n",
    "clean_acc = accuracy_score(y_test_int, y_pred_clean_int)\n",
    "print(f\"Baseline (Clean) Accuracy: {clean_acc * 100:.2f}%\")\n",
    "\n",
    "classifier = KerasClassifier(model=model, clip_values=(X_test.min(), X_test.max()))\n",
    "print(\"ART Classifier created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165bff81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating FGSM attack samples (epsilon=0.1)...\n",
      "This may take a few minutes depending on dataset size...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahima/Desktop/ENC/env/lib/python3.12/site-packages/art/estimators/classification/keras.py:305: UserWarning: Loss function is a plain function, not a Keras loss object. Cannot set reduction; assuming per-sample loss.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial samples generated.\n"
     ]
    }
   ],
   "source": [
    "EPSILON = 0.1\n",
    "\n",
    "print(f\"\\nGenerating FGSM attack samples (epsilon={EPSILON})...\")\n",
    "print(\"This may take a few minutes depending on dataset size...\")\n",
    "\n",
    "attack_fgsm = FastGradientMethod(estimator=classifier, eps=EPSILON)\n",
    "\n",
    "n_samples = 10000 \n",
    "X_test_subset = X_test[:n_samples]\n",
    "y_test_subset_ohe = y_test_ohe[:n_samples]\n",
    "y_test_subset_int = y_test_int[:n_samples]\n",
    "\n",
    "X_test_adv_fgsm = attack_fgsm.generate(x=X_test_subset)\n",
    "print(\"Adversarial samples generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bf53b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model on FGSM examples...\n",
      "\n",
      "========================================\n",
      "RESULTS: FGSM Attack (eps=0.1)\n",
      "========================================\n",
      "Clean Accuracy (on subset): 90.64%\n",
      "Attack Accuracy:            62.29%\n",
      "Accuracy Drop:              28.58%\n",
      "========================================\n",
      "\n",
      "Classification Report (Adversarial):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          BENIGN       0.65      0.69      0.67      4769\n",
      "             Bot       0.01      0.19      0.01        16\n",
      "            DDoS       0.76      0.66      0.70      1128\n",
      "   DoS GoldenEye       0.12      0.71      0.20        85\n",
      "        DoS Hulk       0.92      0.62      0.74      2207\n",
      "DoS Slowhttptest       0.30      0.71      0.42        51\n",
      "   DoS slowloris       0.22      0.59      0.31        58\n",
      "     FTP-Patator       0.00      0.00      0.00        76\n",
      "      Heartbleed       0.00      0.00      0.00         0\n",
      "    Infiltration       0.00      0.00      0.00         0\n",
      "        PortScan       0.95      0.44      0.60      1553\n",
      "     SSH-Patator       0.04      0.11      0.05        57\n",
      "\n",
      "        accuracy                           0.62     10000\n",
      "       macro avg       0.33      0.39      0.31     10000\n",
      "    weighted avg       0.75      0.62      0.66     10000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3297  305  185  278   70   66  113   66   56  152   37  144]\n",
      " [   0    3    0    0    0    0    0    5    0    0    0    8]\n",
      " [ 230    0  743   55   47    0    0    0    3   50    0    0]\n",
      " [   7    0    4   60    9    0    0    0    0    5    0    0]\n",
      " [ 684    2   39  109 1369    0    1    0    0    0    0    3]\n",
      " [   5    0    0    1    0   36    7    0    0    1    0    1]\n",
      " [   6    0    0    0    0   18   34    0    0    0    0    0]\n",
      " [  75    0    0    0    0    0    0    0    0    0    0    1]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 743  112   11    0    0    1    3    2    0    0  681    0]\n",
      " [  28   21    0    0    0    0    0    2    0    0    0    6]]\n",
      "\n",
      "Saving adversarial samples...\n",
      "✓ Saved: X_adv_fgsm_ids.npy\n",
      "✓ Saved: y_test_fgsm_ids_int.npy\n",
      "✓ Saved: y_test_fgsm_ids_ohe.npy\n",
      "\n",
      "✓ FGSM attack completed successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating model on FGSM examples...\")\n",
    "\n",
    "y_pred_adv = model.predict(X_test_adv_fgsm, verbose=0)\n",
    "y_pred_adv_int = np.argmax(y_pred_adv, axis=1)\n",
    "\n",
    "adv_acc = accuracy_score(y_test_subset_int, y_pred_adv_int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"RESULTS: FGSM Attack (eps={EPSILON})\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Clean Accuracy (on subset): {accuracy_score(y_test_subset_int, np.argmax(model.predict(X_test_subset, verbose=0), axis=1)) * 100:.2f}%\")\n",
    "print(f\"Attack Accuracy:            {adv_acc * 100:.2f}%\")\n",
    "print(f\"Accuracy Drop:              {(clean_acc - adv_acc) * 100:.2f}%\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "print(\"\\nClassification Report (Adversarial):\")\n",
    "print(classification_report(y_test_subset_int, y_pred_adv_int, target_names=class_names, zero_division=0))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_subset_int, y_pred_adv_int))\n",
    "\n",
    "print(\"\\nSaving adversarial samples...\")\n",
    "np.save('X_adv_fgsm_ids.npy', X_test_adv_fgsm)\n",
    "np.save('y_test_fgsm_ids_int.npy', y_test_subset_int)\n",
    "np.save('y_test_fgsm_ids_ohe.npy', y_test_subset_ohe)\n",
    "print(\"✓ Saved: X_adv_fgsm_ids.npy\")\n",
    "print(\"✓ Saved: y_test_fgsm_ids_int.npy\")\n",
    "print(\"✓ Saved: y_test_fgsm_ids_ohe.npy\")\n",
    "\n",
    "print(\"\\n✓ FGSM attack completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
